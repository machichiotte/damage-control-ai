# Architecture Technique - DamageControl AI

## ðŸ— Vue Globale

L'application suit une architecture client-serveur avec traitement IA cÃ´tÃ© backend.

```mermaid
graph TD
    User[Utilisateur] -->|Upload Image| Frontend[Frontend Vue.js]
    Frontend -->|HTTP POST| Backend[Backend FastAPI]
    Backend -->|Stockage Local| Files[SystÃ¨me de Fichiers]
    Backend -->|InfÃ©rence| AI[Depth Anything Model]
    AI -->|Depth Map| Backend
    Backend -->|RÃ©sultats| Frontend
    Frontend -->|Affichage| User
```

## ðŸ”§ Choix Technologiques & Justification

### 1. Frontend : Vue.js 3 + TailwindCSS

**Pourquoi Vue.js ?**

- ExpÃ©rience prÃ©alable avec Vue.js
- Ã‰cosystÃ¨me riche et moderne (Vite, Composition API)
- Excellente rÃ©activitÃ© pour les interfaces dynamiques

**TailwindCSS :**

- Design rapide et moderne
- Utility-first pour un contrÃ´le total
- Dark mode natif

**TresJS (âœ… ImplÃ©mentÃ©) :**

- Ã‰quivalent de React-Three-Fiber pour Vue
- Visualisation 3D interactive des depth maps
- OrbitControls pour rotation/zoom/pan
- Displacement mapping pour relief 3D

### 2. Backend : Python FastAPI

**Pourquoi FastAPI ?**

- Standard de l'industrie pour servir des modÃ¨les IA
- Performance Ã©levÃ©e (asynchrone)
- Documentation automatique (Swagger UI)
- Validation de donnÃ©es avec Pydantic

**Traitement d'images :**

- **OpenCV** : Normalisation et colormap des depth maps
- **PIL/Pillow** : Manipulation d'images
- **NumPy** : Calculs matriciels

### 3. Intelligence Artificielle (Hugging Face + Ultralytics)

**ModÃ¨les utilisÃ©s :**

#### Depth Anything (âœ… ImplÃ©mentÃ©)

- **ModÃ¨le** : `LiheYoung/depth-anything-small-hf`
- **TÃ¢che** : Estimation de profondeur monoculaire
- **Usage** : GÃ©nÃ¨re une carte de profondeur 3D Ã  partir d'une image 2D
- **Performance** : ~2-5 secondes par image (CPU)
- **Visualisation** : Colormap INFERNO (rouge = proche, bleu = loin)

#### YOLOv8 (âœ… ImplÃ©mentÃ©)

- **ModÃ¨le** : `yolov8n.pt` (nano)
- **TÃ¢che** : DÃ©tection d'objets gÃ©nÃ©riques
- **Usage** : Identifier les objets dans l'image (voitures, personnes, camions)
- **Performance** : ~1-2 secondes par image (CPU)
- **Threshold** : 25% de confiance minimum

#### OWL-ViT (âœ… ImplÃ©mentÃ©)

- **ModÃ¨le** : `google/owlvit-base-patch32`
- **TÃ¢che** : Zero-Shot Object Detection
- **Usage** : DÃ©tecter des piÃ¨ces spÃ©cifiques via requÃªtes textuelles (bumper, door, wheel, etc.)
- **Performance** : ~5-10 secondes par image (CPU)
- **Threshold** : 5% de confiance minimum
- **Avantage** : Pas besoin d'entraÃ®nement pour de nouvelles classes

#### TAPAS (PrÃ©vu - Sprint 3)

- **ModÃ¨le** : `google/tapas-base-finetuned-wtq`
- **TÃ¢che** : Question-Answering sur tableaux
- **Usage** : Extraire franchises et garanties depuis des contrats PDF

### 4. Stockage : SystÃ¨me de Fichiers Local

**Pourquoi pas MinIO/S3 pour le MVP ?**

- SimplicitÃ© de dÃ©veloppement
- Pas de dÃ©pendance Docker
- Suffisant pour la preuve de concept

**Structure actuelle :**

```
/backend/uploads/
â”œâ”€â”€ [uuid].jpg                  # Image originale
â”œâ”€â”€ depth_[uuid].jpg            # Depth map gÃ©nÃ©rÃ©e
â”œâ”€â”€ detected_[uuid].jpg         # YOLO annotations
â””â”€â”€ parts_[uuid].jpg            # OWL-ViT annotations
```

**Migration future :**

- Facile Ã  migrer vers S3/MinIO en production
- Changement minimal du code (juste la configuration)

## ðŸ“Š Flux de DonnÃ©es

### 1. Upload d'Image

```
User â†’ Frontend â†’ POST /upload â†’ Backend â†’ Filesystem
                                         â†“
                                    Response (filename, url)
```

### 2. Analyse de Profondeur

```
User â†’ Frontend â†’ POST /analyze/{filename} â†’ Backend
                                              â†“
                                         Load Image
                                              â†“
                                    Depth Anything Model
                                              â†“
                                    Generate Depth Map
                                              â†“
                                    Apply Colormap (OpenCV)
                                              â†“
                                    Save to Filesystem
                                              â†“
                                    Response (depth_map_url, stats)
                                              â†“
                                         Frontend
                                              â†“
                                    Display Side-by-Side
```

## ðŸ”’ SÃ©curitÃ© & Limitations

### SÃ©curitÃ© actuelle :

- Validation du type de fichier (images uniquement)
- Noms de fichiers UUID (Ã©vite les collisions)
- CORS configurÃ© pour localhost uniquement

### Limitations MVP :

- Pas d'authentification utilisateur
- Stockage local (non scalable)
- CPU uniquement (pas de GPU)
- Pas de limite de taille de fichier

### AmÃ©liorations futures :

- Authentification JWT
- Stockage cloud (S3)
- Support GPU pour accÃ©lÃ©ration
- Rate limiting
- Compression d'images

## ðŸ“ˆ Performance

### Temps de traitement (CPU - Intel i7) :

- Upload : < 100ms
- Depth Estimation : 2-5 secondes
- Total (upload + analyse) : ~5 secondes

### Optimisations possibles :

- Utilisation GPU (CUDA) : 10x plus rapide
- ModÃ¨le quantifiÃ© : 2x plus rapide
- Batch processing : Traiter plusieurs images en parallÃ¨le

## ðŸš€ Ã‰volution de l'Architecture

### Phase actuelle (MVP) :

- Monolithe simple
- Stockage local
- CPU uniquement

### Phase 2 (Production) :

- SÃ©paration Frontend/Backend (dÃ©ploiement indÃ©pendant)
- Stockage S3
- GPU pour l'infÃ©rence
- Cache Redis pour les rÃ©sultats

### Phase 3 (Scale) :

- Microservices (service par modÃ¨le IA)
- Queue de traitement (Celery/RabbitMQ)
- Load balancing
- CDN pour les images
